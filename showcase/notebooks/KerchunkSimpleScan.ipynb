{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dddd62-e4c4-4cd0-9422-d6ebfcd42393",
   "metadata": {},
   "source": [
    "# Assess a file for Kerchunkability with Padocc pipeline\n",
    "Take an accepted input (single) file and attempt to convert using known methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82807227-e389-46be-b872-431b579180e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.compute import KerchunkConverter\n",
    "from pipeline.scan import summarise_json\n",
    "\n",
    "nfile     = '/badc/cmip6/data/CMIP6/C4MIP/CCCma/CanESM5/1pctCO2-rad/r1i1p1f1/AERmon/ps/gn/v20190429/ps_AERmon_CanESM5_1pctCO2-rad_r1i1p1f1_gn_185001-200012.nc'\n",
    "\n",
    "converter = KerchunkConverter(bypass_driver=True)\n",
    "refs      = converter.try_all_drivers(nfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef3161-54ed-4744-9cfa-f2f7988aa81e",
   "metadata": {},
   "source": [
    "The kerchunk converter will fail for invalid types for Kerchunking, some solutions may be possible but it may be that your files must instead be converted to Zarr.\n",
    "We can otherwise assess the refs generated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00213a67-cded-4e33-b3d6-6e3f0ce9396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume, cpf, varchunks, ctype = summarise_json(refs, converter.ctype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad3eee-0efd-4b59-8054-98a0524a4a04",
   "metadata": {},
   "source": [
    "Summarised outputs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31873abe-5403-4896-a9b4-f1951deb3cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assessment for selected file:\n",
      "    Size in bytes        : 47520998\n",
      "    Chunks in file       : 5440\n",
      "    Variables            : ['lat', 'lat_bnds', 'lon', 'lon_bnds', 'ps', 'time', 'time_bnds']\n",
      "    Kerchunk Driver Type : hdf5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Assessment for selected file:\n",
    "    Size in bytes        : {volume}\n",
    "    Chunks in file       : {cpf}\n",
    "    Variables            : {list(varchunks.keys())}\n",
    "    Kerchunk Driver Type : {ctype}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467829a-e682-4c92-bd2e-261754d6a88b",
   "metadata": {},
   "source": [
    "`varchunks` contains the chunk size for each variable. Chunk size is N-dimensional, either the whole array for a specific variable or some subsection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00183712-ad63-4590-ad06-0955935eee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat [64]\n",
      "lat_bnds [64, 2]\n",
      "lon [128]\n",
      "lon_bnds [128, 2]\n",
      "ps [1, 64, 128]\n",
      "time [1]\n",
      "time_bnds [1, 2]\n"
     ]
    }
   ],
   "source": [
    "for var in varchunks.keys():\n",
    "    print(var, varchunks[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3a3fd-17fc-49e8-98f2-5b715321b319",
   "metadata": {},
   "source": [
    "From this we can see for example the `lat` dimension is chunked in sets of 64 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc50908-d97f-4267-8bb2-dbb261aa645a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"chunks\":[64],\"compressor\":null,\"dtype\":\"<f8\",\"fill_value\":9.969209968386869e+36,\"filters\":null,\"order\":\"C\",\"shape\":[64],\"zarr_format\":2}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs['refs']['lat/.zarray']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af808ca7-9232-4e87-a7ff-96945e29ca71",
   "metadata": {},
   "source": [
    "Comparing this to the `shape` of the `lat` dimension, we can understand that no internal chunking is present. The whole 64-length array is considered one chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae3cc2b-8510-4615-9758-b6e178dbf388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"chunks\":[1],\"compressor\":null,\"dtype\":\"<f8\",\"fill_value\":null,\"filters\":null,\"order\":\"C\",\"shape\":[1812],\"zarr_format\":2}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs['refs']['time/.zarray']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3112c-f155-4411-b2f2-1ef9c67d8b43",
   "metadata": {},
   "source": [
    "When we contrast this with the `time` array, we can see the shape is 1812 but the chunksize is just 1. Meaning every time value is considered its own chunk.\n",
    "Other tools and functions exist within the pipeline to analyse Kerchunk refs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "008379ad-0dd8-4a7d-b04b-3dfebe47c3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat/.zarray         Shape: [64], Chunks: [64]\n",
      "lat_bnds/.zarray         Shape: [64, 2], Chunks: [64, 2]\n",
      "lon/.zarray         Shape: [128], Chunks: [128]\n",
      "lon_bnds/.zarray         Shape: [128, 2], Chunks: [128, 2]\n",
      "ps/.zarray         Shape: [1812, 64, 128], Chunks: [1, 64, 128]\n",
      "time/.zarray         Shape: [1812], Chunks: [1]\n",
      "time_bnds/.zarray         Shape: [1812, 2], Chunks: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "from pipeline.utils import find_zarrays\n",
    "import json\n",
    "\n",
    "zarrays = find_zarrays(refs)\n",
    "for z in zarrays.keys():\n",
    "    zarray = json.loads(zarrays[z])\n",
    "    print(f\"{z}         Shape: {zarray['shape']}, Chunks: {zarray['chunks']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26945a-6ffd-4ad5-8a67-be5343d5c3e7",
   "metadata": {},
   "source": [
    "From the above, there is a single chunk for each of: lat, lon, lat_bnds, lon_bnds. But there are 1812 chunks for each of: ps, time, time_bnds. So adding these up we get 1816*3 = 5448. There is an 8-chunk discrepancy here, most likely because 8 of the original chunks are filled with NaN values, so Kerchunk ignores these when writing the reference file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_venv",
   "language": "python",
   "name": "build_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
